{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2bc96b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df87fd50",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9442313c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import gzip\n",
    "import os\n",
    "import sys\n",
    "import pickle as pkl\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "505eb211",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'data/'\n",
    "files = [folder+'ctrain.txt', folder+'ctest.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7f65a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'data/'\n",
    "outputFilePath = folder + 'causal-relations.pkl.gz'\n",
    "#Download English word embeddings from here https://www.cs.york.ac.uk/nlp/extvec/\n",
    "embeddingsPath = folder + 'wiki_extvec.gz'\n",
    "files = [folder+'ctrain.txt', folder+'ctest.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a052c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mapping of the labels to integers\n",
    "labelsMapping = {'Other':0, 'Cause-Effect(e1,e2)':1, 'Cause-Effect(e2,e1)':2}\n",
    "words = {}\n",
    "maxSentenceLen = [0,0]\n",
    "minDistance = -30\n",
    "maxDistance = 30\n",
    "\n",
    "for fileIdx in range(len(files)):\n",
    "    file = files[fileIdx]\n",
    "    for line in open(file):\n",
    "        splits = line.strip().split('\\t')\n",
    "        label = splits[0]\n",
    "        sentence = splits[3]        \n",
    "        tokens = sentence.split(\" \")\n",
    "        maxSentenceLen[fileIdx] = max(maxSentenceLen[fileIdx], len(tokens))\n",
    "        for token in tokens:\n",
    "            words[token.lower()] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa7ebb2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Sentence Lengths:  [97, 67]\n"
     ]
    }
   ],
   "source": [
    "print(\"Max Sentence Lengths: \", maxSentenceLen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77a455a",
   "metadata": {},
   "source": [
    "Extended Dependency Based Skip-gram\n",
    "The Extended Dependency Based Skip-gram is a method for training word embeddings using structural information from dependency graphs. In addition to standard word embeddings, it produces embeddings of dependency context features (e.g. det_a, compound_programming, compound_inv_language) which were found to be useful features in several sentence classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "625e9ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# :: Read in word embeddings ::\n",
    "word2Idx = {}\n",
    "wordEmbeddings = []\n",
    "\n",
    "# :: Downloads the embeddings from the York webserver ::\n",
    "if not os.path.isfile(embeddingsPath):\n",
    "    basename = os.path.basename(embeddingsPath)\n",
    "    if basename == 'wiki_extvec.gz':\n",
    "           print(\"Start downloading word embeddings for English using wget ...\")\n",
    "           #os.system(\"wget https://www.cs.york.ac.uk/nlp/extvec/\"+basename+\" -P embeddings/\")\n",
    "           os.system(\"wget https://public.ukp.informatik.tu-darmstadt.de/reimers/2017_english_embeddings/\"+basename+\" -P embeddings/\")\n",
    "    else:\n",
    "        print(embeddingsPath, \"does not exist. Please provide pre-trained embeddings\")\n",
    "        exit()\n",
    "        \n",
    "# :: Load the pre-trained embeddings file ::\n",
    "fEmbeddings = gzip.open(embeddingsPath, \"r\") if embeddingsPath.endswith('.gz') else open(embeddingsPath, encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb013601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pre-trained embeddings file\n"
     ]
    }
   ],
   "source": [
    "print(\"Load pre-trained embeddings file\")\n",
    "for line in fEmbeddings:\n",
    "    \n",
    "    split = line.decode('utf-8').strip().split(\" \")\n",
    "    word = split[0]\n",
    "    \n",
    "    if len(word2Idx) == 0: #Add padding+unknown\n",
    "        word2Idx[\"PADDING_TOKEN\"] = len(word2Idx)\n",
    "        vector = np.zeros(len(split)-1) #Zero vector vor 'PADDING' word\n",
    "        wordEmbeddings.append(vector)\n",
    "        \n",
    "        word2Idx[\"UNKNOWN_TOKEN\"] = len(word2Idx)\n",
    "        vector = np.random.uniform(-0.25, 0.25, len(split)-1)\n",
    "        wordEmbeddings.append(vector)\n",
    "\n",
    "    if word.lower() in words:\n",
    "        vector = np.array([float(num) for num in split[1:]])\n",
    "        wordEmbeddings.append(vector)\n",
    "        word2Idx[word] = len(word2Idx)\n",
    "       \n",
    "        \n",
    "wordEmbeddings = np.array(wordEmbeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3070a02a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape:  (21243, 300)\n",
      "Len words:  23503\n"
     ]
    }
   ],
   "source": [
    "print(\"Embeddings shape: \", wordEmbeddings.shape)\n",
    "print(\"Len words: \", len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40065e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data stored in pkl folder\n"
     ]
    }
   ],
   "source": [
    "# :: Create token matrix ::\n",
    "vectorizer = Vectorizer(word2Idx, labelsMapping, minDistance, maxDistance, max(maxSentenceLen))\n",
    "train_set = vectorizer.vectorizeInput(files[0])\n",
    "test_set = vectorizer.vectorizeInput(files[1])\n",
    "\n",
    "data = {'wordEmbeddings': wordEmbeddings, 'word2Idx': word2Idx, \n",
    "        'train_set': train_set, 'test_set': test_set, 'labels_mapping': labelsMapping, 'max_sentence_length': max(maxSentenceLen), 'min_distance': minDistance, 'max_distance': maxDistance}\n",
    "\n",
    "f = gzip.open(outputFilePath, 'wb')\n",
    "pkl.dump(data, f)\n",
    "f.close()\n",
    "\n",
    "print(\"Data stored in pkl folder\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fc7bff",
   "metadata": {},
   "source": [
    "# Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b79ab03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5bde0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.python.keras\n",
    "from tensorflow.python.keras.models import Model\n",
    "from tensorflow.python.keras.models import load_model\n",
    "from tensorflow.python.keras.layers import Input, Dense, Dropout, Activation, Flatten, concatenate\n",
    "from tensorflow.python.keras.layers import Embedding\n",
    "from tensorflow.python.keras.layers import Convolution1D, MaxPooling1D, GlobalMaxPooling1D\n",
    "from tensorflow.python.keras.regularizers import Regularizer\n",
    "from tensorflow.python.keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4d4e8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "nb_filter = 100\n",
    "filter_length = 3\n",
    "hidden_dims = 100\n",
    "nb_epoch = 30\n",
    "position_dims = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "816b5abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load dataset\n"
     ]
    }
   ],
   "source": [
    "print(\"Load dataset\")\n",
    "f = gzip.open('data/causal-relations.pkl.gz', 'rb')\n",
    "data = pkl.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc5c8fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = data['wordEmbeddings']\n",
    "yTrain, sentenceTrain, positionTrain1, positionTrain2 = data['train_set']\n",
    "yTest, sentenceTest, positionTest1, positionTest2  = data['test_set']\n",
    "\n",
    "max_position = max(np.max(positionTrain1), np.max(positionTrain2))+1\n",
    "\n",
    "n_out = max(yTrain)+1\n",
    "#train_y_cat = np_utils.to_categorical(yTrain, n_out)\n",
    "max_sentence_len = sentenceTrain.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c88380e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentenceTrain:  (8000, 97)\n",
      "positionTrain1:  (8000, 97)\n",
      "yTrain:  (8000,)\n",
      "sentenceTest:  (2717, 97)\n",
      "positionTest1:  (2717, 97)\n",
      "yTest:  (2717,)\n",
      "Embeddings:  (21243, 300)\n"
     ]
    }
   ],
   "source": [
    "print(\"sentenceTrain: \", sentenceTrain.shape)\n",
    "print(\"positionTrain1: \", positionTrain1.shape)\n",
    "print(\"yTrain: \", yTrain.shape)\n",
    "print(\"sentenceTest: \", sentenceTest.shape)\n",
    "print(\"positionTest1: \", positionTest1.shape)\n",
    "print(\"yTest: \", yTest.shape)\n",
    "print(\"Embeddings: \",embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae66f3c7",
   "metadata": {},
   "source": [
    "# Build the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3438afaa",
   "metadata": {},
   "source": [
    "## This is a CNN for relation classification within a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4f8b143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "words_input (InputLayer)        [(None, 97)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "distance1_input (InputLayer)    [(None, 97)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "distance2_input (InputLayer)    [(None, 97)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 97, 300)      6372900     words_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 97, 50)       3200        distance1_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 97, 50)       3200        distance2_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 97, 400)      0           embedding[0][0]                  \n",
      "                                                                 embedding_1[0][0]                \n",
      "                                                                 embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 97, 100)      120100      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d (GlobalMax (None, 100)          0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 100)          0           global_max_pooling1d[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 3)            303         dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 6,499,703\n",
      "Trainable params: 126,803\n",
      "Non-trainable params: 6,372,900\n",
      "__________________________________________________________________________________________________\n",
      "Start training\n"
     ]
    }
   ],
   "source": [
    "words_input = Input(shape=(max_sentence_len,), dtype='int32', name='words_input')\n",
    "words = Embedding(embeddings.shape[0], embeddings.shape[1], weights=[embeddings], trainable=False)(words_input)\n",
    "\n",
    "distance1_input = Input(shape=(max_sentence_len,), dtype='int32', name='distance1_input')\n",
    "distance1 = Embedding(max_position, position_dims)(distance1_input)\n",
    "\n",
    "distance2_input = Input(shape=(max_sentence_len,), dtype='int32', name='distance2_input')\n",
    "distance2 = Embedding(max_position, position_dims)(distance2_input)\n",
    "\n",
    "output = concatenate([words, distance1, distance2])\n",
    "\n",
    "output = Convolution1D(filters=nb_filter,\n",
    "                        kernel_size=filter_length,\n",
    "                        padding='same',\n",
    "                        activation='tanh',\n",
    "                        strides=1)(output)\n",
    "\n",
    "# standard max over time pooling\n",
    "output = GlobalMaxPooling1D()(output)\n",
    "\n",
    "output = Dropout(0.25)(output)\n",
    "output = Dense(n_out, activation='softmax')(output)\n",
    "model = Model(inputs=[words_input, distance1_input, distance2_input], outputs=[output])\n",
    "model.compile(loss='sparse_categorical_crossentropy',optimizer='Adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "print(\"Start training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526f6a53",
   "metadata": {},
   "source": [
    "## Compute f1 score for each epoch in Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9357c231",
   "metadata": {},
   "source": [
    "### Mathematical equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b100d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_prec, max_rec, max_acc, max_f1 = 0,0,0,0\n",
    "\n",
    "def getPrecision(pred_test, yTest, targetLabel):\n",
    "    #Precision for non-vague\n",
    "    targetLabelCount = 0\n",
    "    correctTargetLabelCount = 0\n",
    "    \n",
    "    for idx in range(len(pred_test)): \n",
    "        if pred_test[idx] == targetLabel:\n",
    "            targetLabelCount += 1\n",
    "            \n",
    "            if pred_test[idx] == yTest[idx]:\n",
    "                correctTargetLabelCount += 1\n",
    "    \n",
    "    if correctTargetLabelCount == 0:\n",
    "        return 0\n",
    "    \n",
    "    return float(correctTargetLabelCount) / targetLabelCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3177857b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 6s 47ms/step - loss: 0.3027 - accuracy: 0.9068\n",
      "Accuracy: 0.9580 (max: 0.9580)\n",
      "Non-other Macro-Averaged F1: 0.7431 (max: 0.7431)\n",
      "\n",
      "125/125 [==============================] - 5s 42ms/step - loss: 0.1221 - accuracy: 0.9625\n",
      "Accuracy: 0.9735 (max: 0.9735)\n",
      "Non-other Macro-Averaged F1: 0.8724 (max: 0.8724)\n",
      "\n",
      "125/125 [==============================] - 5s 41ms/step - loss: 0.0764 - accuracy: 0.9737\n",
      "Accuracy: 0.9772 (max: 0.9772)\n",
      "Non-other Macro-Averaged F1: 0.9084 (max: 0.9084)\n",
      "\n",
      "125/125 [==============================] - 6s 46ms/step - loss: 0.0492 - accuracy: 0.9868\n",
      "Accuracy: 0.9790 (max: 0.9790)\n",
      "Non-other Macro-Averaged F1: 0.9134 (max: 0.9134)\n",
      "\n",
      "125/125 [==============================] - 6s 48ms/step - loss: 0.0306 - accuracy: 0.9931\n",
      "Accuracy: 0.9805 (max: 0.9805)\n",
      "Non-other Macro-Averaged F1: 0.9176 (max: 0.9176)\n",
      "\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.0198 - accuracy: 0.9962\n",
      "Accuracy: 0.9787 (max: 0.9805)\n",
      "Non-other Macro-Averaged F1: 0.9170 (max: 0.9176)\n",
      "\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.0114 - accuracy: 0.9987\n",
      "Accuracy: 0.9801 (max: 0.9805)\n",
      "Non-other Macro-Averaged F1: 0.9213 (max: 0.9213)\n",
      "\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.0079 - accuracy: 0.9995\n",
      "Accuracy: 0.9805 (max: 0.9805)\n",
      "Non-other Macro-Averaged F1: 0.9176 (max: 0.9213)\n",
      "\n",
      "125/125 [==============================] - 6s 48ms/step - loss: 0.0052 - accuracy: 1.0000\n",
      "Accuracy: 0.9809 (max: 0.9809)\n",
      "Non-other Macro-Averaged F1: 0.9176 (max: 0.9213)\n",
      "\n",
      "125/125 [==============================] - 6s 46ms/step - loss: 0.0038 - accuracy: 0.9999\n",
      "Accuracy: 0.9809 (max: 0.9809)\n",
      "Non-other Macro-Averaged F1: 0.9170 (max: 0.9213)\n",
      "\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Accuracy: 0.9801 (max: 0.9809)\n",
      "Non-other Macro-Averaged F1: 0.9134 (max: 0.9213)\n",
      "\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Accuracy: 0.9805 (max: 0.9809)\n",
      "Non-other Macro-Averaged F1: 0.9163 (max: 0.9213)\n",
      "\n",
      "125/125 [==============================] - 6s 49ms/step - loss: 0.0023 - accuracy: 0.9999\n",
      "Accuracy: 0.9805 (max: 0.9809)\n",
      "Non-other Macro-Averaged F1: 0.9213 (max: 0.9213)\n",
      "\n",
      "125/125 [==============================] - 7s 53ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Accuracy: 0.9820 (max: 0.9820)\n",
      "Non-other Macro-Averaged F1: 0.9261 (max: 0.9261)\n",
      "\n",
      "125/125 [==============================] - 6s 49ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Accuracy: 0.9809 (max: 0.9820)\n",
      "Non-other Macro-Averaged F1: 0.9219 (max: 0.9261)\n",
      "\n",
      "125/125 [==============================] - 6s 46ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Accuracy: 0.9809 (max: 0.9820)\n",
      "Non-other Macro-Averaged F1: 0.9176 (max: 0.9261)\n",
      "\n",
      "125/125 [==============================] - 6s 46ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Accuracy: 0.9816 (max: 0.9820)\n",
      "Non-other Macro-Averaged F1: 0.9255 (max: 0.9261)\n",
      "\n",
      "125/125 [==============================] - 6s 50ms/step - loss: 9.0077e-04 - accuracy: 1.0000\n",
      "Accuracy: 0.9816 (max: 0.9820)\n",
      "Non-other Macro-Averaged F1: 0.9308 (max: 0.9308)\n",
      "\n",
      "125/125 [==============================] - 7s 59ms/step - loss: 8.0729e-04 - accuracy: 1.0000\n",
      "Accuracy: 0.9820 (max: 0.9820)\n",
      "Non-other Macro-Averaged F1: 0.9261 (max: 0.9308)\n",
      "\n",
      "125/125 [==============================] - 7s 56ms/step - loss: 7.2028e-04 - accuracy: 1.0000\n",
      "Accuracy: 0.9816 (max: 0.9820)\n",
      "Non-other Macro-Averaged F1: 0.9213 (max: 0.9308)\n",
      "\n",
      "125/125 [==============================] - 6s 51ms/step - loss: 6.8508e-04 - accuracy: 1.0000\n",
      "Accuracy: 0.9805 (max: 0.9820)\n",
      "Non-other Macro-Averaged F1: 0.9225 (max: 0.9308)\n",
      "\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 5.5162e-04 - accuracy: 1.0000\n",
      "Accuracy: 0.9812 (max: 0.9820)\n",
      "Non-other Macro-Averaged F1: 0.9219 (max: 0.9308)\n",
      "\n",
      "125/125 [==============================] - 6s 48ms/step - loss: 5.5006e-04 - accuracy: 1.0000\n",
      "Accuracy: 0.9820 (max: 0.9820)\n",
      "Non-other Macro-Averaged F1: 0.9249 (max: 0.9308)\n",
      "\n",
      "125/125 [==============================] - 8s 63ms/step - loss: 4.5276e-04 - accuracy: 1.0000\n",
      "Accuracy: 0.9805 (max: 0.9820)\n",
      "Non-other Macro-Averaged F1: 0.9176 (max: 0.9308)\n",
      "\n",
      "125/125 [==============================] - 8s 61ms/step - loss: 4.0303e-04 - accuracy: 1.0000\n",
      "Accuracy: 0.9812 (max: 0.9820)\n",
      "Non-other Macro-Averaged F1: 0.9261 (max: 0.9308)\n",
      "\n",
      "125/125 [==============================] - 5s 42ms/step - loss: 3.6473e-04 - accuracy: 1.0000\n",
      "Accuracy: 0.9823 (max: 0.9823)\n",
      "Non-other Macro-Averaged F1: 0.9297 (max: 0.9308)\n",
      "\n",
      "125/125 [==============================] - 5s 42ms/step - loss: 3.1278e-04 - accuracy: 1.0000\n",
      "Accuracy: 0.9827 (max: 0.9827)\n",
      "Non-other Macro-Averaged F1: 0.9375 (max: 0.9375)\n",
      "\n",
      "125/125 [==============================] - 5s 41ms/step - loss: 2.6132e-04 - accuracy: 1.0000\n",
      "Accuracy: 0.9816 (max: 0.9827)\n",
      "Non-other Macro-Averaged F1: 0.9297 (max: 0.9375)\n",
      "\n",
      "125/125 [==============================] - 5s 41ms/step - loss: 2.4994e-04 - accuracy: 1.0000\n",
      "Accuracy: 0.9816 (max: 0.9827)\n",
      "Non-other Macro-Averaged F1: 0.9249 (max: 0.9375)\n",
      "\n",
      "125/125 [==============================] - 5s 41ms/step - loss: 2.2579e-04 - accuracy: 1.0000\n",
      "Accuracy: 0.9816 (max: 0.9827)\n",
      "Non-other Macro-Averaged F1: 0.9249 (max: 0.9375)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def predict_classes(prediction):\n",
    "    \n",
    "    return prediction.argmax(axis=-1)\n",
    "\n",
    "for epoch in range(nb_epoch):       \n",
    "    model.fit([sentenceTrain, positionTrain1, positionTrain2], yTrain, batch_size=batch_size, verbose=True,epochs=1)   \n",
    "    pred_test_ini = model.predict([sentenceTest, positionTest1, positionTest2], verbose=False)\n",
    "    pred_test = predict_classes(pred_test_ini)\n",
    "    \n",
    "    dctLabels = np.sum(pred_test)\n",
    "    totalDCTLabels = np.sum(yTest)\n",
    "   \n",
    "    acc =  np.sum(pred_test == yTest) / float(len(yTest))\n",
    "    max_acc = max(max_acc, acc)\n",
    "    print(\"Accuracy: %.4f (max: %.4f)\" % (acc, max_acc))\n",
    "\n",
    "    f1Sum = 0\n",
    "    f1Count = 0\n",
    "    for targetLabel in range(1, max(yTest)):        \n",
    "        prec = getPrecision(pred_test, yTest, targetLabel)\n",
    "        recall = getPrecision(yTest, pred_test, targetLabel)\n",
    "        f1 = 0 if (prec+recall) == 0 else 2*prec*recall/(prec+recall)\n",
    "        f1Sum += f1\n",
    "        f1Count +=1    \n",
    "        \n",
    "        \n",
    "    macroF1 = f1Sum / float(f1Count)    \n",
    "    max_f1 = max(max_f1, macroF1)\n",
    "    print(\"Non-other Macro-Averaged F1: %.4f (max: %.4f)\\n\" % (macroF1, max_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1df5b68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model/causal_rel_model.h5')  # creates a HDF5 file 'my_model.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a550a9",
   "metadata": {},
   "source": [
    "### Add validation_split and EarlyStopping on val_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e635d9c",
   "metadata": {},
   "source": [
    "#### Rebuild the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6ee5618c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "words_input (InputLayer)        [(None, 97)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "distance1_input (InputLayer)    [(None, 97)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "distance2_input (InputLayer)    [(None, 97)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 97, 300)      6372900     words_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 97, 50)       3200        distance1_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 97, 50)       3200        distance2_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 97, 400)      0           embedding_3[0][0]                \n",
      "                                                                 embedding_4[0][0]                \n",
      "                                                                 embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 97, 100)      120100      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 100)          0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 100)          0           global_max_pooling1d_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 3)            303         dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 6,499,703\n",
      "Trainable params: 126,803\n",
      "Non-trainable params: 6,372,900\n",
      "__________________________________________________________________________________________________\n",
      "Start training\n"
     ]
    }
   ],
   "source": [
    "words_input = Input(shape=(max_sentence_len,), dtype='int32', name='words_input')\n",
    "words = Embedding(embeddings.shape[0], embeddings.shape[1], weights=[embeddings], trainable=False)(words_input)\n",
    "\n",
    "distance1_input = Input(shape=(max_sentence_len,), dtype='int32', name='distance1_input')\n",
    "distance1 = Embedding(max_position, position_dims)(distance1_input)\n",
    "\n",
    "distance2_input = Input(shape=(max_sentence_len,), dtype='int32', name='distance2_input')\n",
    "distance2 = Embedding(max_position, position_dims)(distance2_input)\n",
    "\n",
    "output = concatenate([words, distance1, distance2])\n",
    "\n",
    "output = Convolution1D(filters=nb_filter,\n",
    "                        kernel_size=filter_length,\n",
    "                        padding='same',\n",
    "                        activation='tanh',\n",
    "                        strides=1)(output)\n",
    "\n",
    "# standard max over time pooling\n",
    "output = GlobalMaxPooling1D()(output)\n",
    "\n",
    "output = Dropout(0.25)(output)\n",
    "output = Dense(n_out, activation='softmax')(output)\n",
    "model = Model(inputs=[words_input, distance1_input, distance2_input], outputs=[output])\n",
    "model.compile(loss='sparse_categorical_crossentropy',optimizer='Adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "print(\"Start training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "410d2808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/125\n",
      "100/100 [==============================] - 5s 49ms/step - loss: 0.3444 - accuracy: 0.8966 - val_loss: 0.1878 - val_accuracy: 0.9219\n",
      "Epoch 2/125\n",
      "100/100 [==============================] - 5s 51ms/step - loss: 0.1232 - accuracy: 0.9675 - val_loss: 0.1134 - val_accuracy: 0.9531\n",
      "Epoch 3/125\n",
      "100/100 [==============================] - 5s 51ms/step - loss: 0.0715 - accuracy: 0.9794 - val_loss: 0.0859 - val_accuracy: 0.9844\n",
      "Epoch 4/125\n",
      "100/100 [==============================] - 6s 58ms/step - loss: 0.0497 - accuracy: 0.9855 - val_loss: 0.0874 - val_accuracy: 0.9844\n",
      "Epoch 5/125\n",
      "100/100 [==============================] - 5s 50ms/step - loss: 0.0309 - accuracy: 0.9917 - val_loss: 0.0889 - val_accuracy: 0.9844\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "history=model.fit([sentenceTrain, positionTrain1, positionTrain2], yTrain, batch_size=batch_size, verbose=True,epochs=125,validation_steps=1,validation_split=0.2, callbacks=[\n",
    "        EarlyStopping(monitor='val_accuracy', patience=2),\n",
    "        ModelCheckpoint('models/cnn_model.h5')\n",
    "    ],)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfe74ac",
   "metadata": {},
   "source": [
    "### Keras macro custom_F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7bec8c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define F1 measures: F1 = 2 * (precision * recall) / (precision + recall)\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def custom_f1(y_true, y_pred):    \n",
    "    def recall_m(y_true, y_pred):\n",
    "        TP = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        Positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        \n",
    "        recall = TP / (Positives+K.epsilon())    \n",
    "        return recall \n",
    "    \n",
    "    \n",
    "    def precision_m(y_true, y_pred):\n",
    "        TP = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        Pred_Positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    \n",
    "        precision = TP / (Pred_Positives+K.epsilon())\n",
    "        return precision \n",
    "    \n",
    "    precision, recall = precision_m(y_true, y_pred), recall_m(y_true, y_pred)\n",
    "    \n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "275d4f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "words_input (InputLayer)        [(None, 97)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "distance1_input (InputLayer)    [(None, 97)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "distance2_input (InputLayer)    [(None, 97)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_9 (Embedding)         (None, 97, 300)      6372900     words_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_10 (Embedding)        (None, 97, 50)       3200        distance1_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_11 (Embedding)        (None, 97, 50)       3200        distance2_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 97, 400)      0           embedding_9[0][0]                \n",
      "                                                                 embedding_10[0][0]               \n",
      "                                                                 embedding_11[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 97, 100)      120100      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_3 (GlobalM (None, 100)          0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 100)          0           global_max_pooling1d_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 3)            303         dropout_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 6,499,703\n",
      "Trainable params: 126,803\n",
      "Non-trainable params: 6,372,900\n",
      "__________________________________________________________________________________________________\n",
      "Start training\n"
     ]
    }
   ],
   "source": [
    "#Rebuild the model\n",
    "words_input = Input(shape=(max_sentence_len,), dtype='int32', name='words_input')\n",
    "words = Embedding(embeddings.shape[0], embeddings.shape[1], weights=[embeddings], trainable=False)(words_input)\n",
    "\n",
    "distance1_input = Input(shape=(max_sentence_len,), dtype='int32', name='distance1_input')\n",
    "distance1 = Embedding(max_position, position_dims)(distance1_input)\n",
    "\n",
    "distance2_input = Input(shape=(max_sentence_len,), dtype='int32', name='distance2_input')\n",
    "distance2 = Embedding(max_position, position_dims)(distance2_input)\n",
    "\n",
    "output = concatenate([words, distance1, distance2])\n",
    "\n",
    "output = Convolution1D(filters=nb_filter,\n",
    "                        kernel_size=filter_length,\n",
    "                        padding='same',\n",
    "                        activation='tanh',\n",
    "                        strides=1)(output)\n",
    "\n",
    "# standard max over time pooling\n",
    "output = GlobalMaxPooling1D()(output)\n",
    "\n",
    "output = Dropout(0.25)(output)\n",
    "output = Dense(n_out, activation='softmax')(output)\n",
    "model = Model(inputs=[words_input, distance1_input, distance2_input], outputs=[output])\n",
    "model.compile(loss='sparse_categorical_crossentropy',optimizer='Adam', metrics=['accuracy',custom_f1])\n",
    "model.summary()\n",
    "\n",
    "print(\"Start training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8fa14864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/125\n",
      "100/100 [==============================] - 6s 56ms/step - loss: 0.2991 - accuracy: 0.9089 - custom_f1: 0.2435 - val_loss: 0.1407 - val_accuracy: 0.9531 - val_custom_f1: 0.2778\n",
      "Epoch 2/125\n",
      "100/100 [==============================] - 5s 55ms/step - loss: 0.1084 - accuracy: 0.9697 - custom_f1: 0.2253 - val_loss: 0.0886 - val_accuracy: 0.9844 - val_custom_f1: 0.2740\n",
      "Epoch 3/125\n",
      "100/100 [==============================] - 6s 56ms/step - loss: 0.0657 - accuracy: 0.9797 - custom_f1: 0.2242 - val_loss: 0.0807 - val_accuracy: 0.9844 - val_custom_f1: 0.2466\n",
      "Epoch 4/125\n",
      "100/100 [==============================] - 6s 57ms/step - loss: 0.0442 - accuracy: 0.9878 - custom_f1: 0.2233 - val_loss: 0.0852 - val_accuracy: 0.9844 - val_custom_f1: 0.2740\n",
      "Epoch 5/125\n",
      "100/100 [==============================] - 6s 56ms/step - loss: 0.0267 - accuracy: 0.9939 - custom_f1: 0.2182 - val_loss: 0.0831 - val_accuracy: 0.9844 - val_custom_f1: 0.2466\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "history=model.fit([sentenceTrain, positionTrain1, positionTrain2], yTrain, batch_size=batch_size, verbose=True,epochs=125,validation_steps=1,validation_split=0.2, callbacks=[\n",
    "        EarlyStopping(monitor='val_custom_f1', patience=2),\n",
    "        ModelCheckpoint('models/cnn_model_keras_f1.h5')\n",
    "    ],)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258ca047",
   "metadata": {},
   "source": [
    "# Evaluate the model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db36197",
   "metadata": {},
   "source": [
    "### Accuracy graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "2698a377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c123c198",
   "metadata": {},
   "source": [
    "### Loss graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b814a599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2117e6c9",
   "metadata": {},
   "source": [
    "From the plot of loss, we can see that the model has comparable performance on both train and validation datasets (labeled test)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26d5861",
   "metadata": {},
   "source": [
    "### Sklearn micro and macro avg\n",
    "Les moyennes micro et macro (quelle que soit la mtrique) calculent des choses lgrement diffrentes, et donc leur interprtation diffre. Une macro-moyenne calcule la mtrique indpendamment pour chaque classe, puis prend la moyenne (donc toutes les classes sont traites de manire gale), tandis qu'une micro-moyenne agrgera les contributions de toutes les classes pour calculer la mtrique moyenne. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0c8e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('model/causal_rel_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2a28f80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "769ab5b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9423787543676397"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(yTest, pred_test, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f02d6e38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9815973500184026"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(yTest, pred_test, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6c94b4b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.981380741347552"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(yTest, pred_test, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b341e635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99040867, 0.93333333, 0.90339426])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(yTest, pred_test, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ff91db69",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train_ini=model.predict([sentenceTrain, positionTrain1, positionTrain2], verbose=False)\n",
    "pred_train_ini.shape\n",
    "pred_train=predict_classes(pred_train_ini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "72a3df2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6a179b93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      2389\n",
      "           1       0.98      0.89      0.93       134\n",
      "           2       0.92      0.89      0.90       194\n",
      "\n",
      "    accuracy                           0.98      2717\n",
      "   macro avg       0.96      0.92      0.94      2717\n",
      "weighted avg       0.98      0.98      0.98      2717\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yTest, pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "838924aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2375    2   12]\n",
      " [  11  119    4]\n",
      " [  21    0  173]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(yTest, pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "35fa7422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2717, 3)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0727105a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000,)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f3727586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      6997\n",
      "           1       1.00      1.00      1.00       344\n",
      "           2       1.00      1.00      1.00       659\n",
      "\n",
      "    accuracy                           1.00      8000\n",
      "   macro avg       1.00      1.00      1.00      8000\n",
      "weighted avg       1.00      1.00      1.00      8000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yTrain, pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fc51c4",
   "metadata": {},
   "source": [
    "# ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9c4454df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "32f09f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=5, min_lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "99358520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "words_input (InputLayer)        [(None, 97)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "distance1_input (InputLayer)    [(None, 97)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "distance2_input (InputLayer)    [(None, 97)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_12 (Embedding)        (None, 97, 300)      6372900     words_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_13 (Embedding)        (None, 97, 50)       3200        distance1_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_14 (Embedding)        (None, 97, 50)       3200        distance2_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 97, 400)      0           embedding_12[0][0]               \n",
      "                                                                 embedding_13[0][0]               \n",
      "                                                                 embedding_14[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 97, 100)      120100      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_4 (GlobalM (None, 100)          0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 100)          0           global_max_pooling1d_4[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 3)            303         dropout_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 6,499,703\n",
      "Trainable params: 126,803\n",
      "Non-trainable params: 6,372,900\n",
      "__________________________________________________________________________________________________\n",
      "Start training\n"
     ]
    }
   ],
   "source": [
    "words_input = Input(shape=(max_sentence_len,), dtype='int32', name='words_input')\n",
    "words = Embedding(embeddings.shape[0], embeddings.shape[1], weights=[embeddings], trainable=False)(words_input)\n",
    "\n",
    "distance1_input = Input(shape=(max_sentence_len,), dtype='int32', name='distance1_input')\n",
    "distance1 = Embedding(max_position, position_dims)(distance1_input)\n",
    "\n",
    "distance2_input = Input(shape=(max_sentence_len,), dtype='int32', name='distance2_input')\n",
    "distance2 = Embedding(max_position, position_dims)(distance2_input)\n",
    "\n",
    "output = concatenate([words, distance1, distance2])\n",
    "\n",
    "output = Convolution1D(filters=nb_filter,\n",
    "                        kernel_size=filter_length,\n",
    "                        padding='same',\n",
    "                        activation='tanh',\n",
    "                        strides=1)(output)\n",
    "\n",
    "# standard max over time pooling\n",
    "output = GlobalMaxPooling1D()(output)\n",
    "\n",
    "output = Dropout(0.25)(output)\n",
    "output = Dense(n_out, activation='softmax')(output)\n",
    "model = Model(inputs=[words_input, distance1_input, distance2_input], outputs=[output])\n",
    "model.compile(loss='sparse_categorical_crossentropy',optimizer='Adam', metrics=['accuracy',custom_f1])\n",
    "model.summary()\n",
    "\n",
    "print(\"Start training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1cd01067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/125\n",
      "100/100 [==============================] - 4s 41ms/step - loss: 0.2865 - accuracy: 0.9147 - custom_f1: 0.2380 - val_loss: 0.1601 - val_accuracy: 0.9219 - val_custom_f1: 0.2500\n",
      "Epoch 2/125\n",
      "100/100 [==============================] - 4s 41ms/step - loss: 0.1065 - accuracy: 0.9722 - custom_f1: 0.2261 - val_loss: 0.1044 - val_accuracy: 0.9844 - val_custom_f1: 0.2740\n",
      "Epoch 3/125\n",
      "100/100 [==============================] - 4s 41ms/step - loss: 0.0635 - accuracy: 0.9803 - custom_f1: 0.2262 - val_loss: 0.0867 - val_accuracy: 0.9844 - val_custom_f1: 0.2466\n",
      "Epoch 4/125\n",
      "100/100 [==============================] - 4s 41ms/step - loss: 0.0387 - accuracy: 0.9886 - custom_f1: 0.2215 - val_loss: 0.0820 - val_accuracy: 0.9844 - val_custom_f1: 0.2466\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "history=model.fit([sentenceTrain, positionTrain1, positionTrain2], yTrain, batch_size=batch_size, verbose=True,epochs=125,validation_steps=1,validation_split=0.2, callbacks=[\n",
    "        EarlyStopping(monitor='val_accuracy', patience=2),\n",
    "        ModelCheckpoint('models/cnn_model_keras_f1.h5'),reduce_lr\n",
    "    ],)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e43d4a",
   "metadata": {},
   "source": [
    "#  Compute f1 score for each epoch in Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563dacf4",
   "metadata": {},
   "source": [
    "### Split train dataset into train and val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6f2b7a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split train dataset into train and val\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "06939ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentenceTrain0,sentenceVal0, positionTrain01, positionVal01, positionTrain02, positionVal02,yTrain0,yVal0=train_test_split(sentenceTrain, positionTrain1, positionTrain2,yTrain, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a8611e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentenceTrain:  (8000, 97)\n",
      "positionTrain1:  (8000, 97)\n",
      "positionTr2:  (8000, 97)\n"
     ]
    }
   ],
   "source": [
    "print(\"sentenceTrain: \", sentenceTrain.shape)\n",
    "print(\"positionTrain1: \", positionTrain1.shape)\n",
    "print(\"positionTr2: \", positionTrain2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9eea5b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentenceTrain:  (6400, 97)\n",
      "positionTrain1:  (6400, 97)\n",
      "positionTrain2:  (6400, 97)\n",
      "yTrain:  (6400,)\n"
     ]
    }
   ],
   "source": [
    "print(\"sentenceTrain: \", sentenceTrain0.shape)\n",
    "print(\"positionTrain1: \", positionTrain01.shape)\n",
    "print(\"positionTrain2: \", positionTrain02.shape)\n",
    "print(\"yTrain: \", yTrain0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9959503c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentenceVal:  (1600, 97)\n",
      "positionVal1:  (1600, 97)\n",
      "positionVal2:  (1600, 97)\n",
      "yVal:  (1600,)\n"
     ]
    }
   ],
   "source": [
    "print(\"sentenceVal: \", sentenceVal0.shape)\n",
    "print(\"positionVal1: \", positionVal01.shape)\n",
    "print(\"positionVal2: \", positionVal02.shape)\n",
    "print(\"yVal: \", yVal0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "78525f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "words_input (InputLayer)        [(None, 97)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "distance1_input (InputLayer)    [(None, 97)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "distance2_input (InputLayer)    [(None, 97)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 97, 300)      6372900     words_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 97, 50)       3200        distance1_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 97, 50)       3200        distance2_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 97, 400)      0           embedding[0][0]                  \n",
      "                                                                 embedding_1[0][0]                \n",
      "                                                                 embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 97, 100)      120100      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d (GlobalMax (None, 100)          0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 100)          0           global_max_pooling1d[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 3)            303         dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 6,499,703\n",
      "Trainable params: 126,803\n",
      "Non-trainable params: 6,372,900\n",
      "__________________________________________________________________________________________________\n",
      "Start training\n"
     ]
    }
   ],
   "source": [
    "words_input = Input(shape=(max_sentence_len,), dtype='int32', name='words_input')\n",
    "words = Embedding(embeddings.shape[0], embeddings.shape[1], weights=[embeddings], trainable=False)(words_input)\n",
    "\n",
    "distance1_input = Input(shape=(max_sentence_len,), dtype='int32', name='distance1_input')\n",
    "distance1 = Embedding(max_position, position_dims)(distance1_input)\n",
    "\n",
    "distance2_input = Input(shape=(max_sentence_len,), dtype='int32', name='distance2_input')\n",
    "distance2 = Embedding(max_position, position_dims)(distance2_input)\n",
    "\n",
    "output = concatenate([words, distance1, distance2])\n",
    "\n",
    "output = Convolution1D(filters=nb_filter,\n",
    "                        kernel_size=filter_length,\n",
    "                        padding='same',\n",
    "                        activation='tanh',\n",
    "                        strides=1)(output)\n",
    "\n",
    "# standard max over time pooling\n",
    "output = GlobalMaxPooling1D()(output)\n",
    "\n",
    "output = Dropout(0.25)(output)\n",
    "output = Dense(n_out, activation='softmax')(output)\n",
    "#model = Model(inputs=[words_input, distance1_input, distance2_input], outputs=[output])\n",
    "inputs=[words_input, distance1_input, distance2_input]\n",
    "outputs=[output]\n",
    "model=tf.keras.Model(inputs, outputs)\n",
    "model = Model(inputs=[words_input, distance1_input, distance2_input], outputs=[output])\n",
    "model.compile(loss='sparse_categorical_crossentropy',optimizer='Adam', metrics=['accuracy'],run_eagerly=True)\n",
    "model.summary()\n",
    "\n",
    "print(\"Start training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b1512282",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
    "class Metrics(tf.keras.callbacks.Callback):\n",
    "    \n",
    "    def __init__(self,sentenceVal0,positionVal01,positionVal02,yVal0,patience):\n",
    "\n",
    "        self.patience=patience\n",
    "        self.sentenceVal0 =sentenceVal0\n",
    "        self.positionVal01 = positionVal01\n",
    "        self.positionVal02 = positionVal02\n",
    "        self.yVal0 = yVal0 \n",
    "        self.max_f1=0\n",
    "        self.wait=None \n",
    "\n",
    "        \n",
    "    def on_train_begin(self, logs={}):\n",
    "        self._data = []\n",
    "        self.best=-1\n",
    "        self.ema=-1\n",
    "        self.best_diff=-1\n",
    "        self.mean=[]\n",
    "        self.std=[]\n",
    "        self.wait=0\n",
    "        self.val_f1s = []\n",
    "        self.val_recalls = []\n",
    "        self.val_precisions = []\n",
    "    def set_model(self, model):\n",
    "        self.model = model\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        from tensorflow.python.keras import backend as K\n",
    "        from tensorflow.keras.layers import Lambda\n",
    "        f = tf.keras.backend.function([self.model.inputs],[self.model.outputs])\n",
    "        \n",
    "\n",
    "    #####################################Prediction##############################\n",
    "     \n",
    "        pred=np.array(f([[self.sentenceVal0,self.positionVal01,self.positionVal02], True])).reshape(-1,1)\n",
    "        \n",
    "        Y_pred=pred \n",
    "        \n",
    "        Y_pred=np.asarray(Y_pred)\n",
    "\n",
    "        # Calculate mean and standard deviation.\n",
    "        Y_pred_m = np.mean(Y_pred, axis=0)\n",
    "        val_predict = (np.asarray(self.model.predict([sentenceVal0,positionVal01,positionVal02], verbose=False).argmax(axis=-1))).round()\n",
    "        val_targ = np.asarray(yVal0)\n",
    "        _val_f1 = f1_score(val_targ, val_predict,average='macro')\n",
    "        _val_recall = recall_score(val_targ, val_predict,average='macro')\n",
    "        _val_precision = precision_score(val_targ, val_predict,average='macro')\n",
    "        self.val_f1s.append(_val_f1)\n",
    "        self.val_recalls.append(_val_recall)\n",
    "        self.val_precisions.append(_val_precision)\n",
    "        print (\" val_f1: %f  val_precision: %f  val_recall %f\" %(_val_f1, _val_precision, _val_recall))\n",
    "        if(self.val_f1s[-1] >self.max_f1):\n",
    "            self.wait=0\n",
    "            self.max_f1=self.val_f1s[-1]\n",
    "        else :\n",
    "            self.wait+=1\n",
    "            if self.wait >= self.patience:\n",
    "                self.model.stop_training = True        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "70b26716",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = Metrics(words_input,distance1_input,distance2_input,output,patience=2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "69d4f823",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "44b3be58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "100/100 [==============================] - 6s 59ms/step - loss: 0.3562 - accuracy: 0.8897 - val_loss: 0.2411 - val_accuracy: 0.9219\n",
      " val_f1: 0.825806  val_precision: 0.942150  val_recall 0.751732\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 6s 65ms/step - loss: 0.1403 - accuracy: 0.9556 - val_loss: 0.1915 - val_accuracy: 0.9219\n",
      " val_f1: 0.861526  val_precision: 0.936235  val_recall 0.806810\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 7s 66ms/step - loss: 0.0881 - accuracy: 0.9723 - val_loss: 0.1789 - val_accuracy: 0.9531\n",
      " val_f1: 0.879963  val_precision: 0.895751  val_recall 0.867407\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 7s 66ms/step - loss: 0.0621 - accuracy: 0.9809 - val_loss: 0.1853 - val_accuracy: 0.9219\n",
      " val_f1: 0.875011  val_precision: 0.935577  val_recall 0.827486\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 7s 66ms/step - loss: 0.0398 - accuracy: 0.9892 - val_loss: 0.1920 - val_accuracy: 0.9219\n",
      " val_f1: 0.875867  val_precision: 0.948450  val_recall 0.822594\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "history=model.fit([sentenceTrain0, positionTrain01, positionTrain02], yTrain0, batch_size=batch_size, verbose=True,epochs=20,validation_steps=1,validation_data=([sentenceVal0,positionVal01,positionVal02], yVal0), callbacks=[metrics\n",
    "        ,ModelCheckpoint('models/cnn_model_val_f1.h5')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "face8bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss: 0.0871 - accuracy: 0.9881 - val_loss: 0.1239 - val_accuracy: 0.9219\n",
    " val_f1: 0.887510  val_precision: 0.884502  val_recall 0.891561\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "48f87fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 1s 13ms/step - loss: 0.0792 - accuracy: 0.9753\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07920163869857788, 0.9753404259681702]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate([sentenceTest, positionTest1, positionTest2], yTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679ed307",
   "metadata": {},
   "source": [
    "# Set class weights for imbalenced classes:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7b8d6f",
   "metadata": {},
   "source": [
    "In SemEval2010_task8 dataset there are:\n",
    "\n",
    "6996 'Other' relation \n",
    "\n",
    "659  'Cause-Effect(e2,e1)' effect relation\n",
    "\n",
    "344 'Cause-Effect(e1,e2)' causality relation.\n",
    "\n",
    "=> The classes are imbalenced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c41e144",
   "metadata": {},
   "source": [
    "In order to force the algorithm to treat every instance of class 1 as 20 instances of class 0 and  every instance of class 2 as 10 instances of class 0:\n",
    "    class_weight = {0: 1.,\n",
    "                1: 20.,\n",
    "                2: 10.}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "beee115f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "words_input (InputLayer)        [(None, 97)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "distance1_input (InputLayer)    [(None, 97)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "distance2_input (InputLayer)    [(None, 97)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 97, 300)      6372900     words_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 97, 50)       3200        distance1_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 97, 50)       3200        distance2_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 97, 400)      0           embedding[0][0]                  \n",
      "                                                                 embedding_1[0][0]                \n",
      "                                                                 embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 97, 100)      120100      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d (GlobalMax (None, 100)          0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 100)          0           global_max_pooling1d[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 3)            303         dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 6,499,703\n",
      "Trainable params: 126,803\n",
      "Non-trainable params: 6,372,900\n",
      "__________________________________________________________________________________________________\n",
      "Start training\n"
     ]
    }
   ],
   "source": [
    "words_input = Input(shape=(max_sentence_len,), dtype='int32', name='words_input')\n",
    "words = Embedding(embeddings.shape[0], embeddings.shape[1], weights=[embeddings], trainable=False)(words_input)\n",
    "\n",
    "distance1_input = Input(shape=(max_sentence_len,), dtype='int32', name='distance1_input')\n",
    "distance1 = Embedding(max_position, position_dims)(distance1_input)\n",
    "\n",
    "distance2_input = Input(shape=(max_sentence_len,), dtype='int32', name='distance2_input')\n",
    "distance2 = Embedding(max_position, position_dims)(distance2_input)\n",
    "\n",
    "output = concatenate([words, distance1, distance2])\n",
    "\n",
    "output = Convolution1D(filters=nb_filter,\n",
    "                        kernel_size=filter_length,\n",
    "                        padding='same',\n",
    "                        activation='tanh',\n",
    "                        strides=1)(output)\n",
    "\n",
    "# standard max over time pooling\n",
    "output = GlobalMaxPooling1D()(output)\n",
    "\n",
    "output = Dropout(0.25)(output)\n",
    "output = Dense(n_out, activation='softmax')(output)\n",
    "#model = Model(inputs=[words_input, distance1_input, distance2_input], outputs=[output])\n",
    "inputs=[words_input, distance1_input, distance2_input]\n",
    "outputs=[output]\n",
    "model=tf.keras.Model(inputs, outputs)\n",
    "model = Model(inputs=[words_input, distance1_input, distance2_input], outputs=[output])\n",
    "model.compile(loss='sparse_categorical_crossentropy',optimizer='Adam', metrics=['accuracy'],run_eagerly=True)\n",
    "model.summary()\n",
    "\n",
    "print(\"Start training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "60ddc5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving weights\n",
    "model.save_weights('models/model_weights', save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d0c845b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'words_input': <tensorflow.python.keras.engine.input_layer.InputLayer object at 0x7fa8c76b1af0>, 'distance1_input': <tensorflow.python.keras.engine.input_layer.InputLayer object at 0x7fa8c76b1c70>, 'distance2_input': <tensorflow.python.keras.engine.input_layer.InputLayer object at 0x7fa8c76a3580>, 'embedding_3': <tensorflow.python.keras.layers.embeddings.Embedding object at 0x7fa8c76b1ac0>, 'embedding_4': <tensorflow.python.keras.layers.embeddings.Embedding object at 0x7fa8c76b1a90>, 'embedding_5': <tensorflow.python.keras.layers.embeddings.Embedding object at 0x7fa8c76a3d90>, 'concatenate_1': <tensorflow.python.keras.layers.merge.Concatenate object at 0x7fa8c76b5640>, 'conv1d_1': <tensorflow.python.keras.layers.convolutional.Conv1D object at 0x7fa8c76b5f10>, 'global_max_pooling1d_1': <tensorflow.python.keras.layers.pooling.GlobalMaxPooling1D object at 0x7fa8c763fc40>, 'dropout_1': <tensorflow.python.keras.layers.core.Dropout object at 0x7fa8c763fc70>, 'dense_1': <tensorflow.python.keras.layers.core.Dense object at 0x7fa8c7639760>}\n"
     ]
    }
   ],
   "source": [
    "#layer weights from the model \n",
    "layer_dict = dict([(layer.name, layer) for layer in model.layers])\n",
    "print(layer_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c1669acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the same model architecture and compile\n",
    "loaded_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c99253cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0909836292266846, 0.3881250023841858]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This initializes the variables used by the optimizers,\n",
    "# as well as any stateful metric variables\n",
    "loaded_model.train_on_batch([sentenceTrain0, positionTrain01, positionTrain02], yTrain0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5aac4209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words_input\n",
      "distance1_input\n",
      "distance2_input\n",
      "embedding_3\n",
      "embedding_4\n",
      "embedding_5\n",
      "concatenate_1\n",
      "conv1d_1\n",
      "global_max_pooling1d_1\n",
      "dropout_1\n",
      "dense_1\n"
     ]
    }
   ],
   "source": [
    "# loading the weights from base_model\n",
    "for layer in loaded_model.layers:    \n",
    "    layer_name = layer.name\n",
    "    print(layer.name)\n",
    "    layer.set_weights(layer_dict[layer_name].get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6f1a299d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.06584784,  0.04598597, -0.2018772 ],\n",
       "        [-0.11449538,  0.01961733, -0.1315861 ],\n",
       "        [-0.13925493, -0.01714204,  0.1198431 ],\n",
       "        [-0.14184678, -0.14569642, -0.10084689],\n",
       "        [ 0.16244678, -0.17144649,  0.23330697],\n",
       "        [ 0.11243066, -0.07467834, -0.21872064],\n",
       "        [ 0.2350895 , -0.17133927, -0.23790878],\n",
       "        [ 0.12229478, -0.0974419 ,  0.16282296],\n",
       "        [ 0.2002332 , -0.10006623, -0.09923714],\n",
       "        [-0.01594942, -0.01384284,  0.17669639],\n",
       "        [-0.1299595 , -0.14023335,  0.06011204],\n",
       "        [-0.17800587,  0.06013442, -0.14965059],\n",
       "        [-0.20020044, -0.05795054, -0.17513332],\n",
       "        [-0.1377841 ,  0.07657465, -0.04860032],\n",
       "        [ 0.01313025,  0.14049108, -0.14801727],\n",
       "        [-0.09398449, -0.12705463, -0.12970206],\n",
       "        [-0.06437083, -0.06048926,  0.22343053],\n",
       "        [ 0.19503227,  0.12673543,  0.12105651],\n",
       "        [-0.06646761,  0.11810388,  0.1433471 ],\n",
       "        [-0.0564209 , -0.17521441,  0.06036901],\n",
       "        [ 0.10247612, -0.02816309,  0.12775461],\n",
       "        [-0.02883373, -0.05101395, -0.20941314],\n",
       "        [ 0.17261721, -0.14906812, -0.0328977 ],\n",
       "        [ 0.12708464,  0.09986217, -0.02335861],\n",
       "        [-0.17327699, -0.2213817 , -0.04879311],\n",
       "        [ 0.18249924,  0.02077778, -0.02686734],\n",
       "        [ 0.09306592,  0.05643316, -0.03605513],\n",
       "        [ 0.14718705, -0.02949912, -0.05132288],\n",
       "        [-0.14192487, -0.10495324, -0.01787359],\n",
       "        [-0.04803689, -0.08162817,  0.04509626],\n",
       "        [ 0.01512255,  0.0373604 ,  0.23618409],\n",
       "        [ 0.24061844, -0.02289122,  0.10029323],\n",
       "        [ 0.05591881,  0.22392626,  0.15262558],\n",
       "        [ 0.03369781,  0.09353991,  0.04400481],\n",
       "        [-0.16626203, -0.09186938, -0.11651675],\n",
       "        [-0.04005558, -0.04540943,  0.08045933],\n",
       "        [-0.15118463,  0.03814984, -0.04111924],\n",
       "        [-0.05859967,  0.17138736, -0.00844446],\n",
       "        [-0.16666915,  0.01719867,  0.19153042],\n",
       "        [-0.14171454, -0.02188722,  0.0301478 ],\n",
       "        [ 0.10844501,  0.23395279,  0.0432035 ],\n",
       "        [ 0.15811785, -0.18307666,  0.01978744],\n",
       "        [ 0.08028162, -0.11456119,  0.15387864],\n",
       "        [-0.20595056, -0.02091769, -0.00583115],\n",
       "        [-0.22739682, -0.12840047,  0.07514583],\n",
       "        [-0.11472574, -0.19829221, -0.22782065],\n",
       "        [ 0.14160363,  0.10608926, -0.23916271],\n",
       "        [ 0.14619073, -0.00245092, -0.03883823],\n",
       "        [ 0.16883639, -0.1794339 , -0.16361539],\n",
       "        [ 0.07277941,  0.03783726,  0.19451226],\n",
       "        [ 0.10906296,  0.19580317,  0.01934883],\n",
       "        [-0.07742125,  0.1843187 , -0.24205251],\n",
       "        [-0.1085114 ,  0.09325267,  0.11222708],\n",
       "        [ 0.21723667,  0.22479607,  0.14163436],\n",
       "        [ 0.12578371,  0.00349539,  0.02828017],\n",
       "        [-0.230776  ,  0.12736504, -0.1187533 ],\n",
       "        [ 0.07611948,  0.1831901 , -0.04418275],\n",
       "        [-0.03690289,  0.09591694, -0.12893046],\n",
       "        [-0.17006025,  0.05556781, -0.13324007],\n",
       "        [-0.03072385, -0.0132521 , -0.23172925],\n",
       "        [-0.05119352, -0.20568274,  0.10328812],\n",
       "        [ 0.16914026,  0.01778969,  0.12923583],\n",
       "        [ 0.23656932,  0.05175941, -0.03724842],\n",
       "        [-0.16083215,  0.0927029 ,  0.19748423],\n",
       "        [-0.15156958, -0.14887305,  0.23676084],\n",
       "        [-0.21076447,  0.19090395,  0.21625972],\n",
       "        [-0.2377477 , -0.19098526, -0.05860579],\n",
       "        [ 0.16982448, -0.16808231, -0.20784046],\n",
       "        [-0.04656752, -0.13337955, -0.21377154],\n",
       "        [ 0.09527996,  0.08158524,  0.03949994],\n",
       "        [-0.13975081, -0.12405714, -0.22711678],\n",
       "        [-0.11533944,  0.20703243, -0.02688925],\n",
       "        [ 0.1380329 , -0.11583893, -0.12626532],\n",
       "        [ 0.08787563,  0.1529304 ,  0.14349233],\n",
       "        [-0.04415287,  0.23473181, -0.04773303],\n",
       "        [-0.1274237 , -0.18320404, -0.03122078],\n",
       "        [ 0.08768749,  0.20726617,  0.05604715],\n",
       "        [ 0.22462912,  0.03860316,  0.06227821],\n",
       "        [-0.21843635,  0.11888408,  0.20445241],\n",
       "        [ 0.09015805,  0.03034364,  0.1036997 ],\n",
       "        [-0.09773973,  0.05349125, -0.02686186],\n",
       "        [ 0.11679056,  0.08421429, -0.01050248],\n",
       "        [ 0.14045002, -0.14510396,  0.03285649],\n",
       "        [-0.11883056, -0.09114272, -0.14762586],\n",
       "        [-0.01331357, -0.16044946,  0.15653549],\n",
       "        [ 0.20036569,  0.08777394,  0.18486996],\n",
       "        [ 0.17505842,  0.10840591, -0.04810735],\n",
       "        [ 0.04084116, -0.18074964,  0.07447935],\n",
       "        [ 0.18960088,  0.13408463,  0.05810423],\n",
       "        [ 0.10781461,  0.01110594, -0.13590907],\n",
       "        [ 0.21486875, -0.00709608,  0.03992148],\n",
       "        [-0.05793429, -0.19818793,  0.03528278],\n",
       "        [-0.21195269, -0.20646097,  0.2163805 ],\n",
       "        [-0.01244767, -0.07275812,  0.10654657],\n",
       "        [-0.00099339,  0.03619881,  0.20223083],\n",
       "        [-0.16724454,  0.15107822,  0.00186885],\n",
       "        [ 0.03867705,  0.0336722 ,  0.11198606],\n",
       "        [-0.0296669 , -0.10968108, -0.10333522],\n",
       "        [ 0.07345496,  0.06731979, -0.13857238],\n",
       "        [ 0.01444897, -0.21744795, -0.22654474]], dtype=float32),\n",
       " array([ 0.00099999, -0.00099999, -0.00099999], dtype=float32)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accessing weights of a layer by its name\n",
    "layer_dict[layer_name].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "decae856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 2s 18ms/step - loss: 0.6317 - accuracy: 0.8793\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6316894292831421, 0.8792786002159119]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the evaluation before and after are same\n",
    "loaded_model.evaluate([sentenceTest, positionTest1, positionTest2], yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d8bab40a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'embedding_3/embeddings:0' shape=(21243, 300) dtype=float32, numpy=\n",
      "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.06115359, -0.12306087, -0.19337489, ...,  0.11880438,\n",
      "        -0.17970166, -0.21234585],\n",
      "       [ 0.152895  , -0.037006  ,  0.12676   , ...,  0.09854   ,\n",
      "         0.530776  , -0.232594  ],\n",
      "       ...,\n",
      "       [ 0.008987  ,  0.003346  ,  0.048075  , ...,  0.601451  ,\n",
      "         0.218893  ,  0.045559  ],\n",
      "       [ 0.1964    , -0.546759  , -0.395152  , ..., -0.148597  ,\n",
      "         0.909782  , -0.701796  ],\n",
      "       [ 0.537103  ,  0.356573  ,  0.528078  , ..., -0.283193  ,\n",
      "         0.23536   , -0.152445  ]], dtype=float32)>, <tf.Variable 'embedding_4/embeddings:0' shape=(64, 50) dtype=float32, numpy=\n",
      "array([[-0.01413449, -0.03184837, -0.02254126, ..., -0.01360248,\n",
      "        -0.00582602, -0.02421376],\n",
      "       [ 0.04195855,  0.03802381,  0.04594328, ..., -0.03400361,\n",
      "        -0.01472078, -0.04502352],\n",
      "       [ 0.03862108, -0.04309344, -0.0013459 , ..., -0.03683268,\n",
      "         0.01788851, -0.04476555],\n",
      "       ...,\n",
      "       [ 0.02104896, -0.04193529,  0.0196903 , ..., -0.01022489,\n",
      "        -0.0343793 , -0.01397334],\n",
      "       [-0.04536662, -0.00713145,  0.02795844, ..., -0.03839145,\n",
      "         0.01692633, -0.0052613 ],\n",
      "       [-0.04001999, -0.00552784, -0.00143527, ...,  0.04536265,\n",
      "        -0.02041405,  0.01038393]], dtype=float32)>, <tf.Variable 'embedding_5/embeddings:0' shape=(64, 50) dtype=float32, numpy=\n",
      "array([[ 0.04830157, -0.00542817,  0.02135384, ..., -0.02913629,\n",
      "        -0.0113735 ,  0.04297219],\n",
      "       [ 0.02644404,  0.0132111 , -0.03854311, ...,  0.01355821,\n",
      "        -0.04178439,  0.03411862],\n",
      "       [ 0.01468915, -0.01733764, -0.03648489, ..., -0.00472093,\n",
      "        -0.04572917, -0.01845752],\n",
      "       ...,\n",
      "       [ 0.03906697,  0.04536386, -0.01126048, ...,  0.03327112,\n",
      "        -0.02483572,  0.02158574],\n",
      "       [ 0.01088905,  0.02679954,  0.04983665, ..., -0.03663471,\n",
      "        -0.0311223 , -0.0489359 ],\n",
      "       [ 0.01005935, -0.02578791,  0.0447904 , ..., -0.02129357,\n",
      "         0.00851243, -0.04377376]], dtype=float32)>, <tf.Variable 'conv1d_1/kernel:0' shape=(3, 400, 100) dtype=float32, numpy=\n",
      "array([[[-0.00507071, -0.00039673, -0.02465847, ..., -0.05647158,\n",
      "          0.05614496, -0.01297942],\n",
      "        [-0.00821557,  0.02737056,  0.00999852, ..., -0.03227293,\n",
      "          0.00431783, -0.04628729],\n",
      "        [-0.02534308, -0.05058526, -0.03825686, ..., -0.02265584,\n",
      "         -0.0582969 ,  0.03394016],\n",
      "        ...,\n",
      "        [-0.03733208,  0.0498448 ,  0.01555366, ...,  0.04274078,\n",
      "         -0.01406952, -0.01219147],\n",
      "        [ 0.00861675,  0.03687861,  0.0258475 , ..., -0.05990437,\n",
      "          0.05678   , -0.0294391 ],\n",
      "        [ 0.00068859, -0.0429515 , -0.03754487, ..., -0.02466287,\n",
      "         -0.06047805,  0.02280748]],\n",
      "\n",
      "       [[ 0.02049248,  0.02061673,  0.03644485, ...,  0.00278512,\n",
      "          0.06180113, -0.03802937],\n",
      "        [-0.00207164,  0.03695224,  0.02582275, ...,  0.03734899,\n",
      "         -0.0228738 , -0.03673885],\n",
      "        [ 0.03886787,  0.00790009,  0.0578972 , ..., -0.05420984,\n",
      "         -0.01316977, -0.04726592],\n",
      "        ...,\n",
      "        [-0.01914638,  0.00516843,  0.04424009, ...,  0.0242757 ,\n",
      "          0.01220725, -0.05304152],\n",
      "        [-0.01286087,  0.03574341,  0.01263171, ...,  0.04581955,\n",
      "          0.01740211, -0.00252135],\n",
      "        [ 0.01442958, -0.034379  ,  0.01045687, ...,  0.06105699,\n",
      "         -0.04622761, -0.05875753]],\n",
      "\n",
      "       [[ 0.01140019,  0.03480808,  0.05622923, ..., -0.05599968,\n",
      "         -0.00916862, -0.03721914],\n",
      "        [ 0.00604031,  0.0234495 ,  0.0181011 , ..., -0.0565897 ,\n",
      "          0.06079746,  0.05042293],\n",
      "        [-0.04293856,  0.04928457,  0.01792777, ..., -0.00879599,\n",
      "         -0.05770829, -0.04637952],\n",
      "        ...,\n",
      "        [ 0.05397952,  0.01983694,  0.02070646, ..., -0.03518964,\n",
      "          0.00239822, -0.06141581],\n",
      "        [-0.01660559, -0.03268738,  0.01107715, ..., -0.00372803,\n",
      "          0.03093102, -0.04956659],\n",
      "        [-0.05656432, -0.04530869,  0.00957078, ..., -0.05588912,\n",
      "         -0.05672286,  0.04834973]]], dtype=float32)>, <tf.Variable 'conv1d_1/bias:0' shape=(100,) dtype=float32, numpy=\n",
      "array([ 0.00099996, -0.00099987, -0.00099997, -0.00099964,  0.00099994,\n",
      "        0.00099997,  0.00099998,  0.00099992,  0.00099998, -0.0009999 ,\n",
      "       -0.00099992, -0.00099994, -0.00099991, -0.00099996,  0.00099961,\n",
      "        0.00099979, -0.00099995,  0.0009999 , -0.00099997, -0.00099914,\n",
      "        0.00099984,  0.00099993,  0.00099997,  0.0009999 , -0.00099984,\n",
      "        0.00099997,  0.00099991,  0.00099996, -0.00099992, -0.00099976,\n",
      "       -0.00099995,  0.00099996, -0.00099994, -0.00099979, -0.00099989,\n",
      "       -0.00099986, -0.00099996, -0.00099996, -0.00099997, -0.00099994,\n",
      "       -0.00099978,  0.00099997,  0.00099983, -0.00099997, -0.00099997,\n",
      "        0.00099991,  0.00099997,  0.00099996,  0.00099998, -0.00099986,\n",
      "        0.00099705, -0.00099985, -0.00099997,  0.00099975,  0.0009999 ,\n",
      "       -0.00099997,  0.00099919, -0.00099963, -0.00099994,  0.00099989,\n",
      "       -0.00099931,  0.00099993,  0.00099997, -0.00099998, -0.00099997,\n",
      "       -0.00099998, -0.00099994,  0.00099998,  0.00099995,  0.00099968,\n",
      "        0.0009998 , -0.00099996,  0.00099997, -0.00099988, -0.00099995,\n",
      "       -0.00099971, -0.00099981,  0.00099996, -0.00099998,  0.00099964,\n",
      "       -0.00099993,  0.00099991,  0.00099997, -0.00098534, -0.00099966,\n",
      "        0.00099988,  0.00099995,  0.00099991,  0.00099992,  0.00099995,\n",
      "        0.00099996,  0.00099949, -0.00099997, -0.00099981, -0.00099994,\n",
      "       -0.00099997, -0.00099983,  0.00099991,  0.00099994,  0.00099997],\n",
      "      dtype=float32)>, <tf.Variable 'dense_1/kernel:0' shape=(100, 3) dtype=float32, numpy=\n",
      "array([[ 0.06584784,  0.04598597, -0.2018772 ],\n",
      "       [-0.11449538,  0.01961733, -0.1315861 ],\n",
      "       [-0.13925493, -0.01714204,  0.1198431 ],\n",
      "       [-0.14184678, -0.14569642, -0.10084689],\n",
      "       [ 0.16244678, -0.17144649,  0.23330697],\n",
      "       [ 0.11243066, -0.07467834, -0.21872064],\n",
      "       [ 0.2350895 , -0.17133927, -0.23790878],\n",
      "       [ 0.12229478, -0.0974419 ,  0.16282296],\n",
      "       [ 0.2002332 , -0.10006623, -0.09923714],\n",
      "       [-0.01594942, -0.01384284,  0.17669639],\n",
      "       [-0.1299595 , -0.14023335,  0.06011204],\n",
      "       [-0.17800587,  0.06013442, -0.14965059],\n",
      "       [-0.20020044, -0.05795054, -0.17513332],\n",
      "       [-0.1377841 ,  0.07657465, -0.04860032],\n",
      "       [ 0.01313025,  0.14049108, -0.14801727],\n",
      "       [-0.09398449, -0.12705463, -0.12970206],\n",
      "       [-0.06437083, -0.06048926,  0.22343053],\n",
      "       [ 0.19503227,  0.12673543,  0.12105651],\n",
      "       [-0.06646761,  0.11810388,  0.1433471 ],\n",
      "       [-0.0564209 , -0.17521441,  0.06036901],\n",
      "       [ 0.10247612, -0.02816309,  0.12775461],\n",
      "       [-0.02883373, -0.05101395, -0.20941314],\n",
      "       [ 0.17261721, -0.14906812, -0.0328977 ],\n",
      "       [ 0.12708464,  0.09986217, -0.02335861],\n",
      "       [-0.17327699, -0.2213817 , -0.04879311],\n",
      "       [ 0.18249924,  0.02077778, -0.02686734],\n",
      "       [ 0.09306592,  0.05643316, -0.03605513],\n",
      "       [ 0.14718705, -0.02949912, -0.05132288],\n",
      "       [-0.14192487, -0.10495324, -0.01787359],\n",
      "       [-0.04803689, -0.08162817,  0.04509626],\n",
      "       [ 0.01512255,  0.0373604 ,  0.23618409],\n",
      "       [ 0.24061844, -0.02289122,  0.10029323],\n",
      "       [ 0.05591881,  0.22392626,  0.15262558],\n",
      "       [ 0.03369781,  0.09353991,  0.04400481],\n",
      "       [-0.16626203, -0.09186938, -0.11651675],\n",
      "       [-0.04005558, -0.04540943,  0.08045933],\n",
      "       [-0.15118463,  0.03814984, -0.04111924],\n",
      "       [-0.05859967,  0.17138736, -0.00844446],\n",
      "       [-0.16666915,  0.01719867,  0.19153042],\n",
      "       [-0.14171454, -0.02188722,  0.0301478 ],\n",
      "       [ 0.10844501,  0.23395279,  0.0432035 ],\n",
      "       [ 0.15811785, -0.18307666,  0.01978744],\n",
      "       [ 0.08028162, -0.11456119,  0.15387864],\n",
      "       [-0.20595056, -0.02091769, -0.00583115],\n",
      "       [-0.22739682, -0.12840047,  0.07514583],\n",
      "       [-0.11472574, -0.19829221, -0.22782065],\n",
      "       [ 0.14160363,  0.10608926, -0.23916271],\n",
      "       [ 0.14619073, -0.00245092, -0.03883823],\n",
      "       [ 0.16883639, -0.1794339 , -0.16361539],\n",
      "       [ 0.07277941,  0.03783726,  0.19451226],\n",
      "       [ 0.10906296,  0.19580317,  0.01934883],\n",
      "       [-0.07742125,  0.1843187 , -0.24205251],\n",
      "       [-0.1085114 ,  0.09325267,  0.11222708],\n",
      "       [ 0.21723667,  0.22479607,  0.14163436],\n",
      "       [ 0.12578371,  0.00349539,  0.02828017],\n",
      "       [-0.230776  ,  0.12736504, -0.1187533 ],\n",
      "       [ 0.07611948,  0.1831901 , -0.04418275],\n",
      "       [-0.03690289,  0.09591694, -0.12893046],\n",
      "       [-0.17006025,  0.05556781, -0.13324007],\n",
      "       [-0.03072385, -0.0132521 , -0.23172925],\n",
      "       [-0.05119352, -0.20568274,  0.10328812],\n",
      "       [ 0.16914026,  0.01778969,  0.12923583],\n",
      "       [ 0.23656932,  0.05175941, -0.03724842],\n",
      "       [-0.16083215,  0.0927029 ,  0.19748423],\n",
      "       [-0.15156958, -0.14887305,  0.23676084],\n",
      "       [-0.21076447,  0.19090395,  0.21625972],\n",
      "       [-0.2377477 , -0.19098526, -0.05860579],\n",
      "       [ 0.16982448, -0.16808231, -0.20784046],\n",
      "       [-0.04656752, -0.13337955, -0.21377154],\n",
      "       [ 0.09527996,  0.08158524,  0.03949994],\n",
      "       [-0.13975081, -0.12405714, -0.22711678],\n",
      "       [-0.11533944,  0.20703243, -0.02688925],\n",
      "       [ 0.1380329 , -0.11583893, -0.12626532],\n",
      "       [ 0.08787563,  0.1529304 ,  0.14349233],\n",
      "       [-0.04415287,  0.23473181, -0.04773303],\n",
      "       [-0.1274237 , -0.18320404, -0.03122078],\n",
      "       [ 0.08768749,  0.20726617,  0.05604715],\n",
      "       [ 0.22462912,  0.03860316,  0.06227821],\n",
      "       [-0.21843635,  0.11888408,  0.20445241],\n",
      "       [ 0.09015805,  0.03034364,  0.1036997 ],\n",
      "       [-0.09773973,  0.05349125, -0.02686186],\n",
      "       [ 0.11679056,  0.08421429, -0.01050248],\n",
      "       [ 0.14045002, -0.14510396,  0.03285649],\n",
      "       [-0.11883056, -0.09114272, -0.14762586],\n",
      "       [-0.01331357, -0.16044946,  0.15653549],\n",
      "       [ 0.20036569,  0.08777394,  0.18486996],\n",
      "       [ 0.17505842,  0.10840591, -0.04810735],\n",
      "       [ 0.04084116, -0.18074964,  0.07447935],\n",
      "       [ 0.18960088,  0.13408463,  0.05810423],\n",
      "       [ 0.10781461,  0.01110594, -0.13590907],\n",
      "       [ 0.21486875, -0.00709608,  0.03992148],\n",
      "       [-0.05793429, -0.19818793,  0.03528278],\n",
      "       [-0.21195269, -0.20646097,  0.2163805 ],\n",
      "       [-0.01244767, -0.07275812,  0.10654657],\n",
      "       [-0.00099339,  0.03619881,  0.20223083],\n",
      "       [-0.16724454,  0.15107822,  0.00186885],\n",
      "       [ 0.03867705,  0.0336722 ,  0.11198606],\n",
      "       [-0.0296669 , -0.10968108, -0.10333522],\n",
      "       [ 0.07345496,  0.06731979, -0.13857238],\n",
      "       [ 0.01444897, -0.21744795, -0.22654474]], dtype=float32)>, <tf.Variable 'dense_1/bias:0' shape=(3,) dtype=float32, numpy=array([ 0.00099999, -0.00099999, -0.00099999], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "print(loaded_model.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "39138c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'embedding_3/embeddings:0' shape=(21243, 300) dtype=float32, numpy=\n",
      "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.06115359, -0.12306087, -0.19337489, ...,  0.11880438,\n",
      "        -0.17970166, -0.21234585],\n",
      "       [ 0.152895  , -0.037006  ,  0.12676   , ...,  0.09854   ,\n",
      "         0.530776  , -0.232594  ],\n",
      "       ...,\n",
      "       [ 0.008987  ,  0.003346  ,  0.048075  , ...,  0.601451  ,\n",
      "         0.218893  ,  0.045559  ],\n",
      "       [ 0.1964    , -0.546759  , -0.395152  , ..., -0.148597  ,\n",
      "         0.909782  , -0.701796  ],\n",
      "       [ 0.537103  ,  0.356573  ,  0.528078  , ..., -0.283193  ,\n",
      "         0.23536   , -0.152445  ]], dtype=float32)>, <tf.Variable 'embedding_4/embeddings:0' shape=(64, 50) dtype=float32, numpy=\n",
      "array([[-0.01413449, -0.03184837, -0.02254126, ..., -0.01360248,\n",
      "        -0.00582602, -0.02421376],\n",
      "       [ 0.04195855,  0.03802381,  0.04594328, ..., -0.03400361,\n",
      "        -0.01472078, -0.04502352],\n",
      "       [ 0.03862108, -0.04309344, -0.0013459 , ..., -0.03683268,\n",
      "         0.01788851, -0.04476555],\n",
      "       ...,\n",
      "       [ 0.02104896, -0.04193529,  0.0196903 , ..., -0.01022489,\n",
      "        -0.0343793 , -0.01397334],\n",
      "       [-0.04536662, -0.00713145,  0.02795844, ..., -0.03839145,\n",
      "         0.01692633, -0.0052613 ],\n",
      "       [-0.04001999, -0.00552784, -0.00143527, ...,  0.04536265,\n",
      "        -0.02041405,  0.01038393]], dtype=float32)>, <tf.Variable 'embedding_5/embeddings:0' shape=(64, 50) dtype=float32, numpy=\n",
      "array([[ 0.04830157, -0.00542817,  0.02135384, ..., -0.02913629,\n",
      "        -0.0113735 ,  0.04297219],\n",
      "       [ 0.02644404,  0.0132111 , -0.03854311, ...,  0.01355821,\n",
      "        -0.04178439,  0.03411862],\n",
      "       [ 0.01468915, -0.01733764, -0.03648489, ..., -0.00472093,\n",
      "        -0.04572917, -0.01845752],\n",
      "       ...,\n",
      "       [ 0.03906697,  0.04536386, -0.01126048, ...,  0.03327112,\n",
      "        -0.02483572,  0.02158574],\n",
      "       [ 0.01088905,  0.02679954,  0.04983665, ..., -0.03663471,\n",
      "        -0.0311223 , -0.0489359 ],\n",
      "       [ 0.01005935, -0.02578791,  0.0447904 , ..., -0.02129357,\n",
      "         0.00851243, -0.04377376]], dtype=float32)>, <tf.Variable 'conv1d_1/kernel:0' shape=(3, 400, 100) dtype=float32, numpy=\n",
      "array([[[-0.00507071, -0.00039673, -0.02465847, ..., -0.05647158,\n",
      "          0.05614496, -0.01297942],\n",
      "        [-0.00821557,  0.02737056,  0.00999852, ..., -0.03227293,\n",
      "          0.00431783, -0.04628729],\n",
      "        [-0.02534308, -0.05058526, -0.03825686, ..., -0.02265584,\n",
      "         -0.0582969 ,  0.03394016],\n",
      "        ...,\n",
      "        [-0.03733208,  0.0498448 ,  0.01555366, ...,  0.04274078,\n",
      "         -0.01406952, -0.01219147],\n",
      "        [ 0.00861675,  0.03687861,  0.0258475 , ..., -0.05990437,\n",
      "          0.05678   , -0.0294391 ],\n",
      "        [ 0.00068859, -0.0429515 , -0.03754487, ..., -0.02466287,\n",
      "         -0.06047805,  0.02280748]],\n",
      "\n",
      "       [[ 0.02049248,  0.02061673,  0.03644485, ...,  0.00278512,\n",
      "          0.06180113, -0.03802937],\n",
      "        [-0.00207164,  0.03695224,  0.02582275, ...,  0.03734899,\n",
      "         -0.0228738 , -0.03673885],\n",
      "        [ 0.03886787,  0.00790009,  0.0578972 , ..., -0.05420984,\n",
      "         -0.01316977, -0.04726592],\n",
      "        ...,\n",
      "        [-0.01914638,  0.00516843,  0.04424009, ...,  0.0242757 ,\n",
      "          0.01220725, -0.05304152],\n",
      "        [-0.01286087,  0.03574341,  0.01263171, ...,  0.04581955,\n",
      "          0.01740211, -0.00252135],\n",
      "        [ 0.01442958, -0.034379  ,  0.01045687, ...,  0.06105699,\n",
      "         -0.04622761, -0.05875753]],\n",
      "\n",
      "       [[ 0.01140019,  0.03480808,  0.05622923, ..., -0.05599968,\n",
      "         -0.00916862, -0.03721914],\n",
      "        [ 0.00604031,  0.0234495 ,  0.0181011 , ..., -0.0565897 ,\n",
      "          0.06079746,  0.05042293],\n",
      "        [-0.04293856,  0.04928457,  0.01792777, ..., -0.00879599,\n",
      "         -0.05770829, -0.04637952],\n",
      "        ...,\n",
      "        [ 0.05397952,  0.01983694,  0.02070646, ..., -0.03518964,\n",
      "          0.00239822, -0.06141581],\n",
      "        [-0.01660559, -0.03268738,  0.01107715, ..., -0.00372803,\n",
      "          0.03093102, -0.04956659],\n",
      "        [-0.05656432, -0.04530869,  0.00957078, ..., -0.05588912,\n",
      "         -0.05672286,  0.04834973]]], dtype=float32)>, <tf.Variable 'conv1d_1/bias:0' shape=(100,) dtype=float32, numpy=\n",
      "array([ 0.00099996, -0.00099987, -0.00099997, -0.00099964,  0.00099994,\n",
      "        0.00099997,  0.00099998,  0.00099992,  0.00099998, -0.0009999 ,\n",
      "       -0.00099992, -0.00099994, -0.00099991, -0.00099996,  0.00099961,\n",
      "        0.00099979, -0.00099995,  0.0009999 , -0.00099997, -0.00099914,\n",
      "        0.00099984,  0.00099993,  0.00099997,  0.0009999 , -0.00099984,\n",
      "        0.00099997,  0.00099991,  0.00099996, -0.00099992, -0.00099976,\n",
      "       -0.00099995,  0.00099996, -0.00099994, -0.00099979, -0.00099989,\n",
      "       -0.00099986, -0.00099996, -0.00099996, -0.00099997, -0.00099994,\n",
      "       -0.00099978,  0.00099997,  0.00099983, -0.00099997, -0.00099997,\n",
      "        0.00099991,  0.00099997,  0.00099996,  0.00099998, -0.00099986,\n",
      "        0.00099705, -0.00099985, -0.00099997,  0.00099975,  0.0009999 ,\n",
      "       -0.00099997,  0.00099919, -0.00099963, -0.00099994,  0.00099989,\n",
      "       -0.00099931,  0.00099993,  0.00099997, -0.00099998, -0.00099997,\n",
      "       -0.00099998, -0.00099994,  0.00099998,  0.00099995,  0.00099968,\n",
      "        0.0009998 , -0.00099996,  0.00099997, -0.00099988, -0.00099995,\n",
      "       -0.00099971, -0.00099981,  0.00099996, -0.00099998,  0.00099964,\n",
      "       -0.00099993,  0.00099991,  0.00099997, -0.00098534, -0.00099966,\n",
      "        0.00099988,  0.00099995,  0.00099991,  0.00099992,  0.00099995,\n",
      "        0.00099996,  0.00099949, -0.00099997, -0.00099981, -0.00099994,\n",
      "       -0.00099997, -0.00099983,  0.00099991,  0.00099994,  0.00099997],\n",
      "      dtype=float32)>, <tf.Variable 'dense_1/kernel:0' shape=(100, 3) dtype=float32, numpy=\n",
      "array([[ 0.06584784,  0.04598597, -0.2018772 ],\n",
      "       [-0.11449538,  0.01961733, -0.1315861 ],\n",
      "       [-0.13925493, -0.01714204,  0.1198431 ],\n",
      "       [-0.14184678, -0.14569642, -0.10084689],\n",
      "       [ 0.16244678, -0.17144649,  0.23330697],\n",
      "       [ 0.11243066, -0.07467834, -0.21872064],\n",
      "       [ 0.2350895 , -0.17133927, -0.23790878],\n",
      "       [ 0.12229478, -0.0974419 ,  0.16282296],\n",
      "       [ 0.2002332 , -0.10006623, -0.09923714],\n",
      "       [-0.01594942, -0.01384284,  0.17669639],\n",
      "       [-0.1299595 , -0.14023335,  0.06011204],\n",
      "       [-0.17800587,  0.06013442, -0.14965059],\n",
      "       [-0.20020044, -0.05795054, -0.17513332],\n",
      "       [-0.1377841 ,  0.07657465, -0.04860032],\n",
      "       [ 0.01313025,  0.14049108, -0.14801727],\n",
      "       [-0.09398449, -0.12705463, -0.12970206],\n",
      "       [-0.06437083, -0.06048926,  0.22343053],\n",
      "       [ 0.19503227,  0.12673543,  0.12105651],\n",
      "       [-0.06646761,  0.11810388,  0.1433471 ],\n",
      "       [-0.0564209 , -0.17521441,  0.06036901],\n",
      "       [ 0.10247612, -0.02816309,  0.12775461],\n",
      "       [-0.02883373, -0.05101395, -0.20941314],\n",
      "       [ 0.17261721, -0.14906812, -0.0328977 ],\n",
      "       [ 0.12708464,  0.09986217, -0.02335861],\n",
      "       [-0.17327699, -0.2213817 , -0.04879311],\n",
      "       [ 0.18249924,  0.02077778, -0.02686734],\n",
      "       [ 0.09306592,  0.05643316, -0.03605513],\n",
      "       [ 0.14718705, -0.02949912, -0.05132288],\n",
      "       [-0.14192487, -0.10495324, -0.01787359],\n",
      "       [-0.04803689, -0.08162817,  0.04509626],\n",
      "       [ 0.01512255,  0.0373604 ,  0.23618409],\n",
      "       [ 0.24061844, -0.02289122,  0.10029323],\n",
      "       [ 0.05591881,  0.22392626,  0.15262558],\n",
      "       [ 0.03369781,  0.09353991,  0.04400481],\n",
      "       [-0.16626203, -0.09186938, -0.11651675],\n",
      "       [-0.04005558, -0.04540943,  0.08045933],\n",
      "       [-0.15118463,  0.03814984, -0.04111924],\n",
      "       [-0.05859967,  0.17138736, -0.00844446],\n",
      "       [-0.16666915,  0.01719867,  0.19153042],\n",
      "       [-0.14171454, -0.02188722,  0.0301478 ],\n",
      "       [ 0.10844501,  0.23395279,  0.0432035 ],\n",
      "       [ 0.15811785, -0.18307666,  0.01978744],\n",
      "       [ 0.08028162, -0.11456119,  0.15387864],\n",
      "       [-0.20595056, -0.02091769, -0.00583115],\n",
      "       [-0.22739682, -0.12840047,  0.07514583],\n",
      "       [-0.11472574, -0.19829221, -0.22782065],\n",
      "       [ 0.14160363,  0.10608926, -0.23916271],\n",
      "       [ 0.14619073, -0.00245092, -0.03883823],\n",
      "       [ 0.16883639, -0.1794339 , -0.16361539],\n",
      "       [ 0.07277941,  0.03783726,  0.19451226],\n",
      "       [ 0.10906296,  0.19580317,  0.01934883],\n",
      "       [-0.07742125,  0.1843187 , -0.24205251],\n",
      "       [-0.1085114 ,  0.09325267,  0.11222708],\n",
      "       [ 0.21723667,  0.22479607,  0.14163436],\n",
      "       [ 0.12578371,  0.00349539,  0.02828017],\n",
      "       [-0.230776  ,  0.12736504, -0.1187533 ],\n",
      "       [ 0.07611948,  0.1831901 , -0.04418275],\n",
      "       [-0.03690289,  0.09591694, -0.12893046],\n",
      "       [-0.17006025,  0.05556781, -0.13324007],\n",
      "       [-0.03072385, -0.0132521 , -0.23172925],\n",
      "       [-0.05119352, -0.20568274,  0.10328812],\n",
      "       [ 0.16914026,  0.01778969,  0.12923583],\n",
      "       [ 0.23656932,  0.05175941, -0.03724842],\n",
      "       [-0.16083215,  0.0927029 ,  0.19748423],\n",
      "       [-0.15156958, -0.14887305,  0.23676084],\n",
      "       [-0.21076447,  0.19090395,  0.21625972],\n",
      "       [-0.2377477 , -0.19098526, -0.05860579],\n",
      "       [ 0.16982448, -0.16808231, -0.20784046],\n",
      "       [-0.04656752, -0.13337955, -0.21377154],\n",
      "       [ 0.09527996,  0.08158524,  0.03949994],\n",
      "       [-0.13975081, -0.12405714, -0.22711678],\n",
      "       [-0.11533944,  0.20703243, -0.02688925],\n",
      "       [ 0.1380329 , -0.11583893, -0.12626532],\n",
      "       [ 0.08787563,  0.1529304 ,  0.14349233],\n",
      "       [-0.04415287,  0.23473181, -0.04773303],\n",
      "       [-0.1274237 , -0.18320404, -0.03122078],\n",
      "       [ 0.08768749,  0.20726617,  0.05604715],\n",
      "       [ 0.22462912,  0.03860316,  0.06227821],\n",
      "       [-0.21843635,  0.11888408,  0.20445241],\n",
      "       [ 0.09015805,  0.03034364,  0.1036997 ],\n",
      "       [-0.09773973,  0.05349125, -0.02686186],\n",
      "       [ 0.11679056,  0.08421429, -0.01050248],\n",
      "       [ 0.14045002, -0.14510396,  0.03285649],\n",
      "       [-0.11883056, -0.09114272, -0.14762586],\n",
      "       [-0.01331357, -0.16044946,  0.15653549],\n",
      "       [ 0.20036569,  0.08777394,  0.18486996],\n",
      "       [ 0.17505842,  0.10840591, -0.04810735],\n",
      "       [ 0.04084116, -0.18074964,  0.07447935],\n",
      "       [ 0.18960088,  0.13408463,  0.05810423],\n",
      "       [ 0.10781461,  0.01110594, -0.13590907],\n",
      "       [ 0.21486875, -0.00709608,  0.03992148],\n",
      "       [-0.05793429, -0.19818793,  0.03528278],\n",
      "       [-0.21195269, -0.20646097,  0.2163805 ],\n",
      "       [-0.01244767, -0.07275812,  0.10654657],\n",
      "       [-0.00099339,  0.03619881,  0.20223083],\n",
      "       [-0.16724454,  0.15107822,  0.00186885],\n",
      "       [ 0.03867705,  0.0336722 ,  0.11198606],\n",
      "       [-0.0296669 , -0.10968108, -0.10333522],\n",
      "       [ 0.07345496,  0.06731979, -0.13857238],\n",
      "       [ 0.01444897, -0.21744795, -0.22654474]], dtype=float32)>, <tf.Variable 'dense_1/bias:0' shape=(3,) dtype=float32, numpy=array([ 0.00099999, -0.00099999, -0.00099999], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "print(model.weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4bfb1d",
   "metadata": {},
   "source": [
    "# class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f2081895",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight = {0: 1.,\n",
    "                1: 20.,\n",
    "                2: 10.}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f313c833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "words_input (InputLayer)        [(None, 97)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "distance1_input (InputLayer)    [(None, 97)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "distance2_input (InputLayer)    [(None, 97)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 97, 300)      6372900     words_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_7 (Embedding)         (None, 97, 50)       3200        distance1_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_8 (Embedding)         (None, 97, 50)       3200        distance2_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 97, 400)      0           embedding_6[0][0]                \n",
      "                                                                 embedding_7[0][0]                \n",
      "                                                                 embedding_8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 97, 100)      120100      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_2 (GlobalM (None, 100)          0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 100)          0           global_max_pooling1d_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 3)            303         dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 6,499,703\n",
      "Trainable params: 126,803\n",
      "Non-trainable params: 6,372,900\n",
      "__________________________________________________________________________________________________\n",
      "Start training\n"
     ]
    }
   ],
   "source": [
    "words_input = Input(shape=(max_sentence_len,), dtype='int32', name='words_input')\n",
    "words = Embedding(embeddings.shape[0], embeddings.shape[1], weights=[embeddings], trainable=False)(words_input)\n",
    "\n",
    "distance1_input = Input(shape=(max_sentence_len,), dtype='int32', name='distance1_input')\n",
    "distance1 = Embedding(max_position, position_dims)(distance1_input)\n",
    "\n",
    "distance2_input = Input(shape=(max_sentence_len,), dtype='int32', name='distance2_input')\n",
    "distance2 = Embedding(max_position, position_dims)(distance2_input)\n",
    "\n",
    "output = concatenate([words, distance1, distance2])\n",
    "\n",
    "output = Convolution1D(filters=nb_filter,\n",
    "                        kernel_size=filter_length,\n",
    "                        padding='same',\n",
    "                        activation='tanh',\n",
    "                        strides=1)(output)\n",
    "\n",
    "# standard max over time pooling\n",
    "output = GlobalMaxPooling1D()(output)\n",
    "\n",
    "output = Dropout(0.25)(output)\n",
    "output = Dense(n_out, activation='softmax')(output)\n",
    "#model = Model(inputs=[words_input, distance1_input, distance2_input], outputs=[output])\n",
    "inputs=[words_input, distance1_input, distance2_input]\n",
    "outputs=[output]\n",
    "model=tf.keras.Model(inputs, outputs)\n",
    "model = Model(inputs=[words_input, distance1_input, distance2_input], outputs=[output])\n",
    "model.compile(loss='sparse_categorical_crossentropy',optimizer='Adam', metrics=['accuracy'],run_eagerly=True)\n",
    "model.summary()\n",
    "\n",
    "print(\"Start training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c8ab6ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "100/100 [==============================] - 6s 57ms/step - loss: 1.9745 - accuracy: 0.7800 - val_loss: 0.4995 - val_accuracy: 0.8438\n",
      " val_f1: 0.749582  val_precision: 0.702170  val_recall 0.848245\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 6s 57ms/step - loss: 0.8163 - accuracy: 0.9323 - val_loss: 0.2517 - val_accuracy: 0.9062\n",
      " val_f1: 0.830915  val_precision: 0.781555  val_recall 0.897562\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 6s 65ms/step - loss: 0.4174 - accuracy: 0.9567 - val_loss: 0.2070 - val_accuracy: 0.9219\n",
      " val_f1: 0.842733  val_precision: 0.799414  val_recall 0.898368\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 7s 66ms/step - loss: 0.2529 - accuracy: 0.9728 - val_loss: 0.2074 - val_accuracy: 0.9062\n",
      " val_f1: 0.843378  val_precision: 0.803487  val_recall 0.901153\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 7s 72ms/step - loss: 0.1620 - accuracy: 0.9798 - val_loss: 0.1233 - val_accuracy: 0.9531\n",
      " val_f1: 0.894825  val_precision: 0.890881  val_recall 0.901623\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 7s 69ms/step - loss: 0.1176 - accuracy: 0.9858 - val_loss: 0.1220 - val_accuracy: 0.9375\n",
      " val_f1: 0.891565  val_precision: 0.899632  val_recall 0.885361\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 7s 71ms/step - loss: 0.0871 - accuracy: 0.9881 - val_loss: 0.1239 - val_accuracy: 0.9219\n",
      " val_f1: 0.887510  val_precision: 0.884502  val_recall 0.891561\n"
     ]
    }
   ],
   "source": [
    "#history=model.fit([sentenceTrain, positionTrain1, positionTrain2], yTrain, batch_size=batch_size, verbose=True,epochs=20,validation_steps=1,validation_split=0.2, callbacks=[metrics])\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "history=model.fit([sentenceTrain0, positionTrain01, positionTrain02], yTrain0, batch_size=batch_size, verbose=True,epochs=20,validation_steps=1,validation_data=([sentenceVal0,positionVal01,positionVal02], yVal0), callbacks=[metrics\n",
    "        ,ModelCheckpoint('models/cnn_model_1.h5')], class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "98dba872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 1s 12ms/step - loss: 0.0873 - accuracy: 0.9746\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08733908832073212, 0.9746043682098389]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the evaluation before and after are same\n",
    "model.evaluate([sentenceTest, positionTest1, positionTest2], yTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bda335",
   "metadata": {},
   "source": [
    "# Class weight with sklearn.utils.class_weight.compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4a4a72bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9606cc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=np.array([0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aed3f749",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = sklearn.utils.class_weight.compute_class_weight('balanced', classes, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f235a544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.38111572, 7.75193798, 4.04653515])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "39440375",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight = {0: 0.38111572,\n",
    "                1: 7.75193798,\n",
    "                2: 4.04653515}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f4067f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "100/100 [==============================] - 7s 64ms/step - loss: 0.7865 - accuracy: 0.7262 - val_loss: 0.4258 - val_accuracy: 0.8750\n",
      " val_f1: 0.768291  val_precision: 0.704249  val_recall 0.874164\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 7s 65ms/step - loss: 0.2864 - accuracy: 0.9292 - val_loss: 0.2329 - val_accuracy: 0.9219\n",
      " val_f1: 0.872883  val_precision: 0.854274  val_recall 0.904241\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 6s 65ms/step - loss: 0.1490 - accuracy: 0.9588 - val_loss: 0.2262 - val_accuracy: 0.9219\n",
      " val_f1: 0.858084  val_precision: 0.818587  val_recall 0.910511\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 6s 65ms/step - loss: 0.0917 - accuracy: 0.9716 - val_loss: 0.1848 - val_accuracy: 0.9531\n",
      " val_f1: 0.863188  val_precision: 0.832254  val_recall 0.901412\n"
     ]
    }
   ],
   "source": [
    "#history=model.fit([sentenceTrain, positionTrain1, positionTrain2], yTrain, batch_size=batch_size, verbose=True,epochs=20,validation_steps=1,validation_split=0.2, callbacks=[metrics])\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "history=model.fit([sentenceTrain0, positionTrain01, positionTrain02], yTrain0, batch_size=batch_size, verbose=True,epochs=20,validation_steps=1,validation_data=([sentenceVal0,positionVal01,positionVal02], yVal0), callbacks=[metrics\n",
    "        ,ModelCheckpoint('models/cnn_model_1.h5')], class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1f4dc4d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 1s 15ms/step - loss: 0.1332 - accuracy: 0.9628\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.13324923813343048, 0.962826669216156]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the evaluation before and after are same\n",
    "model.evaluate([sentenceTest, positionTest1, positionTest2], yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe08b527",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ebb2fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc269dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6ebb83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f66a3cf",
   "metadata": {},
   "source": [
    "# Testing on a benchmark dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7e99749d",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'data/'\n",
    "files = [folder+'my_ctest2.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bb39cb4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load dataset\n"
     ]
    }
   ],
   "source": [
    "print(\"Load dataset\")\n",
    "f = gzip.open(folder + 'causal-relations.pkl.gz', 'rb')\n",
    "data = pkl.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "98c066f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxSentenceLen = data['max_sentence_length']\n",
    "word2Idx = data['word2Idx']\n",
    "labelsMapping = data['labels_mapping']\n",
    "minDistance = data['min_distance']\n",
    "maxDistance = data['max_distance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "591d97d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Sentence Lengths:  97\n"
     ]
    }
   ],
   "source": [
    "print(\"Max Sentence Lengths: \", maxSentenceLen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3bf9f2ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files ['data/my_ctest2.txt']\n"
     ]
    }
   ],
   "source": [
    "vectorizer = Vectorizer(word2Idx, labelsMapping, minDistance, maxDistance, maxSentenceLen)\n",
    "print('files',files)\n",
    "yTest, sentenceTest, positionTest1, positionTest2 = vectorizer.vectorizeInput1(files[0])\n",
    "\n",
    "#model = load_model('model/causal_rel_model.h5')\n",
    "#model = load_model('models/cnn_model_val_f1.h5')\n",
    "model = load_model('models/cnn_model_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "54232a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test_ini = model.predict([sentenceTest, positionTest1, positionTest2], verbose=False)\n",
    "pred_test = pred_test_ini.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2df406b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test result:\n",
      "[2 1 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(\"test result:\")\n",
    "print(pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acb0677",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
